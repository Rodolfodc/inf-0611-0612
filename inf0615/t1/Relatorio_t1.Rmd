---
title: INF0615 -- Aprendizado de Máquina Supervisionado
output: pdf_document
subtitle: Trabalho 1 - Regressão Linear
author: 
- Nicole Nogueira Silva
- Rodolfo Dalla Costa
header-includes:
- \usepackage[brazil, english, portuguese]{babel}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, error = FALSE, message = FALSE, warning = FALSE, tidy = FALSE, fig.align='center')
options(digits = 3)
library(tidyverse)
library(knitr)
library(corrplot)
library(kableExtra)
library(magrittr)

setwd("C:/Users/nicol/Documents/Mineração de dados/inf-0611-0612/inf0615")

```


```{r}
getHypothesis <- function(real_feature_names, categorical_feature_names=F, degree=3){
    
    hypothesis_string <- "hypothesis <- formula(target ~ "
    for(d in 1:degree){
        for(i in 1:length(real_feature_names)){
            hypothesis_string <- paste(hypothesis_string, 
                                       "I(", real_feature_names[i], "^", d, ") + ",
                                       sep = "")
        }
    }
    
    if(typeof(categorical_feature_names) != "logical"){
        for(i in 1:length(categorical_feature_names)){
            hypothesis_string <- paste(hypothesis_string, 
                                       categorical_feature_names[i], " + ",
                                       sep = "")
        } 
    }
    
    
    hypothesis_string <- substr(hypothesis_string, 1, nchar(hypothesis_string)-3)
    hypothesis_string <- paste(hypothesis_string, ")")
    hypothesis <- eval(parse(text=hypothesis_string))
    return(hypothesis)
}


###################################
####   Define MAE function     ####
MAE <- function(preds, labels){
  mae_values <- round(sum(abs(preds-labels))/length(preds),2)
  return(mae_values)
}

####################################
####   Define MSE function     ####
MSE <- function(preds, labels){
  mse_values <- round(sum((preds-labels)**2)/length(preds),2)
  return(mse_values)
}

###################################
#### Define R-squared function ####
R2 <- function(pred, true){
  rss <- sum((pred - true) ^ 2)
  tss <- sum((true - mean(true)) ^ 2)
  r2 <- round(1 - rss/tss,2)
  return(r2)
}
```


# Introdução

O Monóxido de carbono (CO) é um gás incolor e inflamável produzido com base na queima incompleta de material combustível rico em carbono. Apesar de suas aplicações na indústria, é um gás asfixiante muito tóxico para os seres humanos. Nesse contexto, avaliar a concentração de CO é fundamental para mensurar a qualidade do ar de uma determinada região. 
Dessa forma, o objetivo desse trabalho é desenvolver modelos de regressão linear para predizer a concentração de CO no ar usando um conjunto de dados coletados com diversas informações sobre a característica do ar.


# Banco de dados


```{r}
# Comandos que leem os conjuntos de treino e de validacao
train_set <- read.csv("training_set_air_quality.csv", stringsAsFactors=TRUE)
val_set <- read.csv("validation_set_air_quality.csv", stringsAsFactors=TRUE)
test_set <- read.csv("test_set_air_quality.csv", stringsAsFactors=TRUE )


#Inspecionando o banco de dados
#str(train_set)

summary(train_set[,2:9]) %>% 
  kable("latex",  caption = "\\label{tab:dados}Estatísticas sumárias do banco de dados", booktabs = T) %>% 
  kable_styling(latex_options = "hold_position", font_size = 8)

summary(train_set[,10:ncol(train_set)]) %>% 
  kable("latex", booktabs = T) %>% 
  kable_styling(latex_options = "hold_position", font_size = 8)

```

O banco de dados foi dividido em 3 blocos, um conjunto de treinamento que será utilizado para treinar os modelos, um conjunto de validação para mensurar o desempenho dos modelos e um conjunto de teste. A base de treino possui `r nrow(train_set)` linhas e `r ncol(train_set)` colunas enquanto a base de validação possui `r nrow(val_set)` linhas e as mesmas colunas do conjunto de treino.
Nota-se que o banco de dados não possui dados faltantes, se houvesse, o ideal é avaliar se a informação faltante é erro de preenchimento no momento da coleta ou se realmente traz uma informação relevante. 

A partir do summary apresentado na Tabela \ref{tab:dados} é possível notar que a variável "wd", que indica a direção do vento no momento da coleta, é a única variável categorizada da base. Para lidar com isso, tranformamos a variável utilizando a técnica de One-Hot-encoding.


```{r}
train_set$E <- as.numeric(train_set$wd == "E")
train_set$ENE <- as.numeric(train_set$wd == "ENE")
train_set$ESE <- as.numeric(train_set$wd == "ESE")
train_set$NE <- as.numeric(train_set$wd == "NE")
train_set$NNE <- as.numeric(train_set$wd == "NNE")
train_set$N <- as.numeric(train_set$wd == "N")
train_set$NNW <- as.numeric(train_set$wd == "NNW")
train_set$NW <- as.numeric(train_set$wd == "NW")
train_set$S <- as.numeric(train_set$wd == "S")
train_set$SE <- as.numeric(train_set$wd == "SE")
train_set$SSE <- as.numeric(train_set$wd == "SSE")
train_set$SSW <- as.numeric(train_set$wd == "SSW")
train_set$SW <- as.numeric(train_set$wd == "SW")
train_set$W <- as.numeric(train_set$wd == "W")
train_set$WNW <- as.numeric(train_set$wd == "WNW")
train_set$WSW <- as.numeric(train_set$wd == "WSW")
train_set$wd <- NULL

val_set$E <- as.numeric(val_set$wd == "E")
val_set$ENE <- as.numeric(val_set$wd == "ENE")
val_set$ESE <- as.numeric(val_set$wd == "ESE")
val_set$NE <- as.numeric(val_set$wd == "NE")
val_set$NNE <- as.numeric(val_set$wd == "NNE")
val_set$N <- as.numeric(val_set$wd == "N")
val_set$NNW <- as.numeric(val_set$wd == "NNW")
val_set$NW <- as.numeric(val_set$wd == "NW")
val_set$S <- as.numeric(val_set$wd == "S")
val_set$SE <- as.numeric(val_set$wd == "SE")
val_set$SSE <- as.numeric(val_set$wd == "SSE")
val_set$SSW <- as.numeric(val_set$wd == "SSW")
val_set$SW <- as.numeric(val_set$wd == "SW")
val_set$W <- as.numeric(val_set$wd == "W")
val_set$WNW <- as.numeric(val_set$wd == "WNW")
val_set$WSW <- as.numeric(val_set$wd == "WSW")
val_set$wd <- NULL

test_set$E <- as.numeric(test_set$wd == "E")
test_set$ENE <- as.numeric(test_set$wd == "ENE")
test_set$ESE <- as.numeric(test_set$wd == "ESE")
test_set$NE <- as.numeric(test_set$wd == "NE")
test_set$NNE <- as.numeric(test_set$wd == "NNE")
test_set$N <- as.numeric(test_set$wd == "N")
test_set$NNW <- as.numeric(test_set$wd == "NNW")
test_set$NW <- as.numeric(test_set$wd == "NW")
test_set$S <- as.numeric(test_set$wd == "S")
test_set$SE <- as.numeric(test_set$wd == "SE")
test_set$SSE <- as.numeric(test_set$wd == "SSE")
test_set$SSW <- as.numeric(test_set$wd == "SSW")
test_set$SW <- as.numeric(test_set$wd == "SW")
test_set$W <- as.numeric(test_set$wd == "W")
test_set$WNW <- as.numeric(test_set$wd == "WNW")
test_set$WSW <- as.numeric(test_set$wd == "WSW")
test_set$wd <- NULL

```


# Análise descritiva

Para entender as relações entre as variáveis e a concentração de monóxido de carbono (nosso Target), vamos analisar a distribuição da correlação entre as colunas da base. A Figura \ref{fig:graf1} apresenta um panorama geral da correlação com todas as features. Nota-se que a variável resposta tem correlação considerável com as variáveis PM25, PM10 e NO2.

```{r, fig.cap="\\label{fig:graf1} Correlações 2 a 2 das variáveis.", fig.pos='H'}
cor(train_set) %>%
    corrplot(., type = "lower", tl.col = "black", tl.srt = 45)

```

O gráfico da Figura \ref{fig:graf2} apresenta a distribuição da concentração de CO em relação a concentração de PM2.5 no ar. É possível observar que existe uma relação linear entre as variáveis já que a concentração de CO aumenta conforme o PM2.5 aumenta também, o que indica que ajustar um modelo de regrssão linear pode ser uma estratégia adequada.

```{r, fig.cap="\\label{fig:graf2} Distribuição da concentração de CO e de PM2.5 variando o NO2 e SO2.", fig.pos='H'}
train_set %>%
    sample_n(., size = 10000) %>%
    ggplot(., aes(x=PM2.5, y= target, color = NO2, size = SO2))+
    geom_point(aes(alpha = 0.1)) +
  theme_bw() +
  labs( y = "Concentração de CO")

```


Além disso, como é possível notar por meio da Tabela \ref{tab:dados}, as colunas estão em escalas diferentes, por isso, aplicamos a normalização Z-norma nos dados de treino e os mesmos parâmetros para a validação. Dessa forma, cada feature está padronizada com média zero e desvio padrão correspondente.

```{r}
#Normalização Z-Norma

mean_features <- train_set %>%
  select(-target, -No) %>%
  apply(., 2, mean)


sd_features <- train_set %>%
  select(-target, -No) %>%
  apply(., 2, sd)

train_set[ , -which(names(train_set) %in% c("No","target"))] <- sweep(train_set[ , -which(names(train_set) %in% c("No","target"))], 2, mean_features, "-")

train_set[ , -which(names(train_set) %in% c("No","target"))] <- sweep(train_set[ , -which(names(train_set) %in% c("No","target"))], 2, sd_features, "/")

val_set[ , -which(names(val_set) %in% c("No","target"))] <- sweep(val_set[ , -which(names(val_set) %in% c("No","target"))], 2, mean_features, "-")

val_set[ , -which(names(val_set) %in% c("No","target"))] <- sweep(val_set[ , -which(names(val_set) %in% c("No","target"))], 2, sd_features, "/")


test_set[ , -which(names(test_set) %in% c("No","target"))] <- sweep(test_set[ , -which(names(test_set) %in% c("No","target"))], 2, mean_features, "-")

test_set[ , -which(names(test_set) %in% c("No","target"))] <- sweep(test_set[ , -which(names(test_set) %in% c("No","target"))], 2, sd_features, "/")
```


# Metodologia



```{r}
#Baseline

feature_names <- colnames(train_set[ , -which(names(train_set) %in% c("No","target"))])

hypothesis <- getHypothesis(feature_names, degree = 1)

## Baseline 
baseline <- lm(formula=hypothesis, data=train_set)

valPred <- predict(baseline, val_set)
trainPred <- predict(baseline, train_set)
testPred <- predict(baseline, test_set)

mae_train_baseline <- MAE(trainPred, train_set$target)
mse_train_baseline <- MSE(trainPred, train_set$target)
r2_train_baseline <- R2(trainPred, train_set$target)

result_baseline_train <- cbind(Set = "Treino",mae_train_baseline,mse_train_baseline,r2_train_baseline)

mae_val_baseline <- MAE(valPred, val_set$target)
mse_val_baseline <- MSE(valPred, val_set$target)
r2_val_baseline <- R2(valPred, val_set$target)

result_baseline_val <- cbind(Set = "Validação",mae_val_baseline,mse_val_baseline,r2_val_baseline)

mae_test_baseline <- MAE(testPred, test_set$target)
mse_test_baseline <- MSE(testPred, test_set$target)
r2_test_baseline <- R2(testPred, test_set$target)

result_baseline_test <- cbind(Set = "Teste",mae_test_baseline,mse_test_baseline,r2_test_baseline)

```

Para predizer o valor da concentração do monóxido de carbono, primeiro é importante avaliar um modelo de regressão linear mais simples com todas as variáveis, esse será o baseline. A Tabela \ref{tab:baseline} apresenta as medidas do erro médio (MAE), erro quadrático médio (MSE) e o R2 do baseline para os dados de treino, validação e teste. O baseline apresentou um MAE de `r round(mae_test_baseline,1)` no conjunto de teste. 

```{r}
rbind(result_baseline_train, result_baseline_val,result_baseline_test) %>%
  kable("latex",  caption = "\\label{tab:baseline}Resultado do baseline nos conjuntos de treino, validação e teste", booktabs = T, col.names = c("", "MAE", "MSE", "R2")) %>% 
  kable_styling(latex_options = "hold_position", font_size = 8)
  
```



```{r}
#Combinação de feature
comb1 <- lm(target ~ I(year^1) + I(month^1) + I(day^1) + I(hour^1) + (I(PM2.5^1) + 
    I(PM10^1) + I(SO2^1) + I(NO2^1) + I(O3^1) + I(TEMP^1) + I(PRES^1) + 
    I(DEWP^1))^2 + I(RAIN^1) + I(WSPM^1)+ I(E^1) + I(ENE^1) + I(ESE^1) + 
    I(NE^1) + I(NNE^1) + I(N^1) + I(NNW^1) + I(NW^1) + I(S^1) + 
    I(SE^1) + I(SSE^1) + I(SSW^1) + I(SW^1) + I(W^1) + I(WNW^1) + 
    I(WSW^1), data=train_set)

valPred1 <- predict(comb1, val_set)

mae_val_baseline <- MAE(valPred1, val_set$target)
mse_val_baseline <- MSE(valPred1, val_set$target)
r2_val_baseline <- R2(valPred1, val_set$target)

result_baseline_val1 <- cbind(model = "2 a 2", mae_val_baseline,mse_val_baseline,r2_val_baseline)

comb2 <- lm(target ~ I(year^1) + I(month^1) + I(day^1) + I(hour^1) + (I(PM2.5^1) + 
    I(PM10^1) + I(SO2^1) + I(NO2^1) + I(O3^1) + I(TEMP^1) + I(PRES^1) + 
    I(DEWP^1))^3 + I(RAIN^1) + I(WSPM^1)+ I(E^1) + I(ENE^1) + I(ESE^1) + 
    I(NE^1) + I(NNE^1) + I(N^1) + I(NNW^1) + I(NW^1) + I(S^1) + 
    I(SE^1) + I(SSE^1) + I(SSW^1) + I(SW^1) + I(W^1) + I(WNW^1) + 
    I(WSW^1), data=train_set)

valPred2 <- predict(comb2, val_set)

mae_val_baseline <- MAE(valPred2, val_set$target)
mse_val_baseline <- MSE(valPred2, val_set$target)
r2_val_baseline <- R2(valPred2, val_set$target)

result_baseline_val2 <- cbind(model = "3 a 3", mae_val_baseline,mse_val_baseline,r2_val_baseline)

rbind(result_baseline_val1, result_baseline_val2) %>%
  kable("latex",  caption = "\\label{tab:comb1_2}Resultado das combinações nos conjuntos de treino, validação e teste", booktabs = T, col.names = c("Modelo", "MAE", "MSE", "R2")) %>% 
  kable_styling(latex_options = "hold_position", font_size = 8)


# best model combinação no teste
testPred2 <- predict(comb2, test_set)

mae_test_comb2 <- MAE(testPred2, test_set$target)

```

Para melhorar a predição do CO, vamos criar um modelo com combinação de features. Para esse modelo, vamos utlizar todas as variáveis e combinar 2 a 2 as variáveis PM2.5, PM10, SO2, NO2, O3, TEMP, PRES e DEWP. Os resultados do MAE, MSE e R2 para o conjunto de validação podem ser observados na Tabela \ref{tab:comb1_2}. A primeira linha corresponde aos resultados do modelo com combinação 2 a 2 enquanto a segunda linha é o modelo utilizando a combinação 3 a 3. É possível observar que o o melhor modelo desta categoria foi o modelo com combinação 3 a 3. Aplicando esse modelo no conjunto de teste obtivemos um MAE de `r round(mae_test_comb2,1)`.


```{r}
#polinomial
hypothesis <- getHypothesis(feature_names, degree = 1)

f01 <- formula(hypothesis, data=train_set)

hypothesis <- getHypothesis(feature_names, degree = 2)

f02 <- formula(hypothesis, data=train_set)

hypothesis <- getHypothesis(feature_names, degree = 3)

f03 <- formula(hypothesis, data=train_set)

hypothesis <- getHypothesis(feature_names, degree = 4)

f04 <- formula(hypothesis, data=train_set)

hypothesis <- getHypothesis(feature_names, degree = 5)

f05 <- formula(hypothesis, data=train_set)

hypothesis <- getHypothesis(feature_names, degree = 6)

f06 <- formula(hypothesis, data=train_set)
hypothesis <- getHypothesis(feature_names, degree = 7)

f07 <- formula(hypothesis, data=train_set)

hypothesis <- getHypothesis(feature_names, degree = 8)

f08 <- formula(hypothesis, data=train_set)

hypothesis <- getHypothesis(feature_names, degree = 9)

f09 <- formula(hypothesis, data=train_set)

hypothesis <- getHypothesis(feature_names, degree = 10)

f10 <- formula(hypothesis, data=train_set)


formulas <- list(f01, f02, f03, f04, f05, f06, f07, f08, f09, f10)
total_mae_train_poly <- c(length(formulas))
total_mae_val_poly <- c(length(formulas))

i <- 1
for(i in 1:10){
  model <- lm(formula=formulas[[i]], data=train_set)
  
  valPred <- predict(model, val_set)
  trainPred <- predict(model, train_set)
  
  mae_train <- MAE(trainPred, train_set$target)
  total_mae_train_poly[i] <- mae_train
  
  mae_val <- MAE(valPred, val_set$target)
  total_mae_val_poly[i] <- mae_val
  i <- i + 1
  
}

treino_resumo <- data.frame(grau = seq(1:10), MAE = total_mae_train_poly, set = rep("Treino", 10))
val_resumo <- data.frame(grau = seq(1:10), MAE = total_mae_val_poly, set = rep("Validação", 10))

# best model polinomial 

best_poly <- lm(formula=formulas[[5]], data=train_set)
testPred3 <- predict(best_poly, test_set)

mae_test_poly <- MAE(testPred3, test_set$target)

```

Por fim, vamos testar o modelo de regressão aumentando o grau das features. O gráfico da Figura \ref{fig:mae} apresenta o MAE para cada polinômio no conjunto de treino e validação. Podemos reparar que até o grau 3 estamos com underfitting pois o erro no treino e na validação são altos e muito similares. Porém, a partir do grau 6 temos overfitting já que o erro médio no conjunto de validação começa crescer enquanto no conjunto de treino cai. Dessa forma, o ponto ótimo do modelo dessa categoria é o modelo de grau 5. 
Ajustando o nosso melhor modelo polinomial de grau 5 no conjunto de teste obtivemos um MAE de `r round(mae_test_poly, 2)`.

```{r, fig.cap="\\label{fig:mae} MAE do treino e validação para cada grau.", fig.pos='H'}
rbind(treino_resumo, val_resumo) %>%
  ggplot(., aes(x = as.factor(grau), y = MAE, group = set, color = set)) + 
  geom_line() +
  theme_bw() +
  labs(x = "Complexidade do polinômio", y = "MAE", color = "Data Set")
```

# Conclusão

O modelo que apresentou menor erro médio foi o modelo utilizando todas as variáveis com grau 1 e a combinação 3 a 3 das variáveis que possuem maior correlação com a concentração de monóxido de carbono. O baseline, modelo mais simples, apresentou o pior desempenho quando comparado com os outros. O modelo polinomial apresentou resultados razoáveis porém possui uma complexidade alta e exige muito processamento para treinar. Assim, o modelo com combinação 3 a 3 tem vantagem além de possuir o menor MAE. É interessante observar que, selecionar melhor quais variáveis são mais relevantes para predizer a concentração de CO trouxe ganhos significativos no erro médio. 