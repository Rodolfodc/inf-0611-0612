---
title: INF0615 -- Aprendizado de Máquina Supervisionado
output: pdf_document
subtitle: Trabalho 3 - Regressão Linear
author: 
- Nicole Nogueira Silva
- Rodolfo Dalla Costa
header-includes:
- \usepackage[brazil, english, portuguese]{babel}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, error = FALSE, message = FALSE, warning = FALSE, tidy = FALSE, fig.align='center')
options(digits = 3)

library(tidyverse)
library(knitr)
library(corrplot)
library(kableExtra)
library(magrittr)
library(caret)
library(e1071)
library(reshape2)
library(rpart)
library(rpart.plot)
library(randomForest)


setwd("C:/Users/nicol/Documents/Mineração de dados/inf-0611-0612/inf0615/t3")

```


```{r}
# Funcao que calcula a matriz de confusao relativa para 3 classes
calculaMatrizConfusaoRelativa <- function(cm){
    
    # Aplicamos a transposição para garantir que a referencia
    # fique nas linhas e a predicao nas colunas
    cm_absolute = t(cm$table)
    
    # SEMPRE construam e reportem a matriz de confusao relativa!
    cm_relative = cm_absolute
    
    cm_relative[1,] = round(cm_absolute[1,]/sum(cm_absolute[1,]), digits=2)
    cm_relative[2,] = round(cm_absolute[2,]/sum(cm_absolute[2,]), digits=2)
    cm_relative[3,] = round(cm_absolute[3,]/sum(cm_absolute[3,]), digits=2)
    
    return(cm_relative)  
}

```


# Introdução

Durante o ano de 2020 e 2021, a humanidade foi afetada pela pandemia do vírus COVID-19 que ceifou milhares de vidas e gerou impactos em diversas áreas sociais. Milhões de pessoas de diferentes países foram contaminadas apresentando diferentes quadros clínicos de reação ao vírus. 
Dessa forma, o objetivo desse trabalho é inferir o possível estado do paciente diagnosticado com o vírus COVID-19 dentre tr~es possíveis classes: em tratamento, recuperado ou falecido.

# Banco de dados


```{r}
# Comandos que leem os conjuntos de treino e de validacao
train_val_set <- read.csv("train_val_set_patient_status_covid19.csv", stringsAsFactors = T)
#test_set <- read.csv("test_set_patient_status_covid19.csv", stringsAsFactors=T)

train_val_set <- train_val_set %>% unique()



# Configurem o valor da semente.
set.seed(31) 


# Separanco treino e validacao

randomTrainValIndexes <- createDataPartition(train_val_set$label, p = 0.8, list = F, times = 1)
train_set <- train_val_set[randomTrainValIndexes, ]
val_set  <- train_val_set[-randomTrainValIndexes, ]

```

```{r}

#Inspecionando o banco de dados
str(train_set)

#Existência de dados em ambos os datasets
merge(train_set, val_set)

#### Verificando dados ausentes
any(is.na(train_set))
any(is.na(val_set))
#any(is.na(test_set))


summary(train_set[,9]) %>% 
  kable("latex",  caption = "\\label{tab:dados}Estatísticas sumárias do banco de dados", booktabs = T) %>% 
  kable_styling(latex_options = "hold_position", font_size = 8)

summary(train_set[,10:ncol(train_val_set)]) %>% 
  kable("latex", booktabs = T) %>% 
  kable_styling(latex_options = "hold_position", font_size = 8)

```

O banco de dados provem originalmente de um conjunto de dados reunidos por diversos países no mundo e contém informações como data de internação, se o paciente tem ou não doenças crônicas, entre outras variáveis.

Para a inspeção inicial e compreensão dos banco de dados fornecidos, foi avaliada a quantidade de dados, onde ao todo os bancos de dados fornecidos possuem 15 variáveis, sendo 14 atributos e a outra o nosso target, ou seja, o valor que queremos predizer, totalizando 36421 registros. Buscando por dados faltantes que pudessem impactar nas predições, não foi possível identificar nenhum exemplo que apresentasse dados ausentes. Caso esse fato não fosse verdadeiro, poderíamos atuar com a remoção dos exemplos que tivessem alguma featura nula, desde que a ausência de informações não estivesse correlacionada com algum tipo de comportamento específico que pudesse viesar os resultados do modelo. Foi possível identificar que as features tratavam-se de variáveis contínuas (age, latitude,  longitude, date_onset_symptoms, date_admission_hospital, date_confirmation e date_death_or_discharge) e categóricas (sex, country, lives_in_Wuhan, travel_history_location, chronic_disease_binary, travel_history_binary e label). Neste problema, como a variável resposta é categória, utilizaremos um modelo de classificação a partir de árvores de decisão e florestas aleatórias. É importante ressaltar que nossos labels não são balanceados, isto é,  a target de mortos representa apenas x dos dados, a target de tratamento x e em tratamento y. Estes casos podem ser tratados com técnicas de oversampling ou SMOTE, entre outras. Além disso, foram encontrados valores duplicados no cojunto de dados, que foram excluídos para a realização da análise.

A partir do summary apresentado na Tabela \ref{tab:dados} é possível observar um resumo dos dados.



# Análise descritiva

Para entender as relações entre as variáveis e o estado do paciente (nosso Target), vamos analisar a distribuição da correlação entre as colunas da base. A Figura \ref{fig:graf1} apresenta um panorama geral da correlação com todas as features. Nota-se que a variável resposta tem correlação considerável com as variáveis x

```{r, fig.cap="\\label{fig:graf1} Correlações 2 a 2 das variáveis.", fig.pos='H'}
train_set %>% 
  select_if(is.numeric) %>% 
  cor()%>%
  corrplot(., type = "lower", tl.col = "black", tl.srt = 45)

```


Além disso, como é possível notar por meio da Tabela \ref{tab:dados}, as colunas estão em escalas diferentes, por isso, aplicamos a normalização Z-norma nos dados de treino e os mesmos parâmetros para a validação. Dessa forma, cada feature está padronizada com média zero e desvio padrão correspondente.

```{r}
## Normalizacao Z-norm nas features numéricas

mean_features <- apply(train_set %>% select_if(is.numeric), 2, mean)
sd_features <- apply(train_set %>% select_if(is.numeric), 2, sd)

a <-train_set %>%
  select_if(is.numeric) %>%
  sweep(.,2, mean_features, "-" )


```


# Metodologia



```{r}
#Baseline

treeModelBaseline <- rpart(formula=label ~ age + country + longitude + date_onset_symptoms +
                       date_admission_hospital + lives_in_Wuhan + travel_history_location +
                       date_confirmation + sex + latitude + travel_history_dates +
                       chronic_disease_binary + date_death_or_discharge +
                       travel_history_binary,
                   data=train_set, method="class",
                   control=rpart.control(minsplit=2, cp=0.0, xval = 10),
                   parms= list(split="information"))


importance_per_feature <- treeModelBaseline$variable.importanc
relative_importance <- importance_per_feature/sum(importance_per_feature)
relative_importance

printcp(treeModelBaseline)

minCP <- treeModelBaseline$cptable[which.min(treeModelBaseline$cptable[,"xerror"]),"CP"]
minCP

ptree <- prune(treeModelBaseline, cp=minCP)
summary(ptree)

# Vamos ver a performance no conjunto de valida��o sem a poda
val_pred <- predict(treeModelBaseline, val_set, type="class")

cm <- confusionMatrix(data = as.factor(val_pred), 
                      reference = as.factor(val_set$label))

cm_relative <- calculaMatrizConfusaoRelativa(cm)
cm_relative

acc_bal <- (cm_relative[1,1] + cm_relative[2,2] + cm_relative[3,3])/3
acc_bal

# Agora vamos checar a performance do modelo ap�s a poda
val_pred <- predict(ptree, val_set, type="class")
cm <- confusionMatrix(data = as.factor(val_pred), 
                      reference = as.factor(val_set$label))

cm_relative <- calculaMatrizConfusaoRelativa(cm)
cm_relative

acc_bal <- (cm_relative[1,1] + cm_relative[2,2] + cm_relative[3,3])/3
acc_bal


```

Para inferir o estado do paciente diagnosticado com COVID-19, é valido testar um modelo de árvore de decisão com todas as features e sem poda, esse será o baseline. A Tabela \ref{tab:baseline} apresenta as medidas do erro médio (MAE), erro quadrático médio (MSE) e o R2 do baseline para os dados de treino, validação e teste. O baseline apresentou um MAE de  no conjunto de teste. 

```{r}
rbind(result_baseline_train, result_baseline_val,result_baseline_test) %>%
  kable("latex",  caption = "\\label{tab:baseline}Resultado do baseline nos conjuntos de treino, validação e teste", booktabs = T, col.names = c("", "MAE", "MSE", "R2")) %>% 
  kable_styling(latex_options = "hold_position", font_size = 8)
  
```



```{r}
########## ACC Vs Depth 
# Vamos ver como as acur�cias no conjunto de treinamento e de valida��o
# variam conforme variamos o tamanho limite das arvores
number_of_depths = 20
accPerDepth <- data.frame(depth=numeric(number_of_depths), 
                          accTrain=numeric(number_of_depths), 
                          accVal=numeric(number_of_depths))
summary(accPerDepth)
for (maxDepth in 1:number_of_depths){
    treeModel <- rpart(formula=label ~ age + country + longitude + date_onset_symptoms +
                           date_admission_hospital + lives_in_Wuhan + travel_history_location +
                           date_confirmation + sex + latitude + travel_history_dates +
                           chronic_disease_binary + date_death_or_discharge +
                           travel_history_binar, 
                       data=train_set, method="class",
                       control=rpart.control(minsplit=2, cp=0.0, 
                                             maxdepth=maxDepth, xval = 0),
                       parms= list(split="information"))
    
    # Avaliando no conjunto de treino
    train_pred <- predict(treeModel, train_set, type="class")
    cm_train <- confusionMatrix(data = as.factor(train_pred), 
                                reference = as.factor(train_set$label))
    
    cm_relative_train <- calculaMatrizConfusaoRelativa(cm_train)
    acc_bal_train <- (cm_relative_train[1,1] + cm_relative_train[2,2] + cm_relative_train[3,3])/3
    
    # Avaliando no conjunto de validacao
    val_pred <- predict(treeModel, val_set, type="class")
    cm_val <- confusionMatrix(data = as.factor(val_pred), 
                              reference = as.factor(val_set$label))
    
    cm_relative_val <- calculaMatrizConfusaoRelativa(cm_val)
    acc_bal_val <- (cm_relative_train[1,1] + cm_relative_train[2,2] + cm_relative_train[3,3])/3
    
    accPerDepth[maxDepth,] = c(maxDepth, acc_bal_train, 
                               acc_bal_val)
}

       
```

Para melhorar a predição do CO, vamos criar um modelo com combinação de features. Para esse modelo, vamos utlizar todas as variáveis e combinar 2 a 2 as variáveis PM2.5, PM10, SO2, NO2, O3, TEMP, PRES e DEWP. Os resultados do MAE, MSE e R2 para o conjunto de validação podem ser observados na Tabela \ref{tab:comb1_2}. A primeira linha corresponde aos resultados do modelo com combinação 2 a 2 enquanto a segunda linha é o modelo utilizando a combinação 3 a 3. É possível observar que o o melhor modelo desta categoria foi o modelo com combinação 3 a 3. Aplicando esse modelo no conjunto de teste obtivemos um MAE de `r round(mae_test_comb2,1)`.


```{r , fig.cap="\\label{fig:mae} MAE do treino e validação para cada grau.", fig.pos='H'}
accPerDepth <- melt(accPerDepth, id="depth")
ggplot(data=accPerDepth, aes(x=depth, y=value, colour=variable)) + 
  geom_line() +
  geom_point() +
  theme_bw() +
  labs(x = "Complexidade do polinômio", y = "MAE", color = "Data Set")

```

Por fim, vamos testar o modelo de regressão aumentando o grau das features. O gráfico da Figura \ref{fig:mae} apresenta o MAE para cada polinômio no conjunto de treino e validação. Podemos reparar que até o grau 3 estamos com underfitting pois o erro no treino e na validação são altos e muito similares. Porém, a partir do grau 6 temos overfitting já que o erro médio no conjunto de validação começa crescer enquanto no conjunto de treino cai. Dessa forma, o ponto ótimo do modelo dessa categoria é o modelo de grau 5. 
Ajustando o nosso melhor modelo polinomial de grau 5 no conjunto de teste obtivemos um MAE de `r round(mae_test_poly, 2)`.

# Conclusão

O modelo que apresentou menor erro médio foi o modelo utilizando todas as variáveis com grau 1 e a combinação 3 a 3 das variáveis que possuem maior correlação com a concentração de monóxido de carbono. O baseline, modelo mais simples, apresentou o pior desempenho quando comparado com os outros. O modelo polinomial apresentou resultados razoáveis porém possui uma complexidade alta e exige muito processamento para treinar. Assim, o modelo com combinação 3 a 3 tem vantagem além de possuir o menor MAE. É interessante observar que, selecionar melhor quais variáveis são mais relevantes para predizer a concentração de CO trouxe ganhos significativos no erro médio. 